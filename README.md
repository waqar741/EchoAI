# ğŸ™ï¸ Voice Avatar App

**Real-time AI voice conversation with animated avatar** â€“ built with React + FastAPI.

## Architecture

```
User Voice  â†’  STT (Browser)  â†’  LLM API (Server)  â†’  TTS (Browser)  â†’  Animated Avatar
   â†“              â†“                    â†“                    â†“                  â†“
 Browser       Web Speech API     FastAPI + httpx      Web Speech API     Canvas 60fps
```

| Component   | Technology              | Location | Latency |
|-------------|-------------------------|----------|---------|
| **STT**     | Web Speech API          | Client   | <500ms  |
| **LLM**     | Nominee Life / Qwen2.5  | Server   | ~1â€“3s   |
| **TTS**     | Web Speech API          | Client   | Instant |
| **Avatar**  | Canvas + rAF            | Client   | 60fps   |

## Quick Start

```bash
# One-command dev start:
chmod +x scripts/dev.sh && ./scripts/dev.sh

# Or manually:

# Terminal 1 â€” Backend
cd backend
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
uvicorn app.main:app --reload --port 8000

# Terminal 2 â€” Frontend
cd frontend
npm install
npx vite
```

Open **http://localhost:5173** in Chrome or Edge.

## Tech Stack

### Frontend
- **React 18** + TypeScript + Vite
- **Tailwind CSS** â€“ utility-first styling
- **Zustand** â€“ lightweight state management
- **Web Speech API** â€“ STT & TTS (zero network cost)
- **Canvas API** â€“ 60fps avatar animation

### Backend
- **FastAPI** â€“ async Python web framework
- **httpx** â€“ async HTTP client with connection pooling
- **Pydantic** â€“ request/response validation
- **GZip middleware** â€“ compressed responses

## Skills.sh Best Practices Applied

| Skill | Key Rules |
|-------|-----------|
| **vercel-react-best-practices** | `rerender-use-ref-transient-values`, `rerender-memo`, `async-parallel`, `rendering-hoist-jsx`, `rerender-functional-setstate` |
| **anthropics/frontend-design** | Dark refined theme, DM Sans typography, intentional accent colors, not generic AI slop |
| **web-interface-guidelines** | `aria-label` on icon buttons, `focus-visible` rings, `prefers-reduced-motion`, semantic HTML, `touch-action: manipulation`, no `transition: all` |

## Project Structure

```
voice-avatar-app/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routes/chat.py    # /api/chat + /api/chat/stream
â”‚   â”‚   â”œâ”€â”€ core/config.py        # Env settings (cached singleton)
â”‚   â”‚   â”œâ”€â”€ models/schemas.py     # Pydantic models
â”‚   â”‚   â”œâ”€â”€ services/llm_service.py # Async streaming LLM client
â”‚   â”‚   â””â”€â”€ main.py               # FastAPI app factory
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Avatar/Avatar.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat/{ChatContainer,Message,TranscriptDisplay}.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Controls/{MicButton,StopButton,SettingsPanel}.tsx
â”‚   â”‚   â”‚   â””â”€â”€ UI/StatusIndicator.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceInput.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useSpeechSynthesis.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useChatAPI.ts
â”‚   â”‚   â”‚   â””â”€â”€ useAvatarAnimation.ts
â”‚   â”‚   â”œâ”€â”€ store/chatStore.ts
â”‚   â”‚   â”œâ”€â”€ types/index.ts
â”‚   â”‚   â”œâ”€â”€ utils/{constants,audioUtils}.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ styles/globals.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.js
â””â”€â”€ scripts/{dev,build}.sh
```

## Keyboard Shortcut

| Key     | Action                |
|---------|-----------------------|
| `Space` | Toggle mic / Stop & Send |

## Performance Targets

```
STT latency:      < 500ms
API round-trip:    < 2s (streaming)
TTS start:         < 100ms
Animation:         60fps (16ms frames)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total end-to-end:  < 3s
```
